<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eastwood's ARC Principle: Cross-Domain Unification of Recursive Amplification Across AI, Quantum Computing, and Physics</title>

    <!-- MathJax Configuration -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>

    <!-- Nature-style Typography -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:ital,opsz,wght@0,8..60,300;0,8..60,400;0,8..60,600;0,8..60,700;1,8..60,400&family=Source+Sans+3:wght@400;600;700&display=swap" rel="stylesheet">

    <style>
        :root {
            --nature-red: #c41230;
            --nature-dark: #1a1a1a;
            --nature-grey: #666666;
            --nature-light-grey: #f5f5f5;
            --nature-border: #dddddd;
            --text-body: #333333;
            --accent-blue: #0066cc;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            font-size: 16px;
        }

        body {
            font-family: 'Source Serif 4', Georgia, 'Times New Roman', serif;
            font-size: 1rem;
            line-height: 1.7;
            color: var(--text-body);
            background: #ffffff;
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
        }

        /* Header Styles */
        header {
            border-bottom: 3px solid var(--nature-red);
            padding-bottom: 2rem;
            margin-bottom: 2rem;
        }

        .paper-type {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 0.75rem;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 0.15em;
            color: var(--nature-red);
            margin-bottom: 0.5rem;
        }

        h1 {
            font-family: 'Source Serif 4', Georgia, serif;
            font-size: 2.25rem;
            font-weight: 700;
            line-height: 1.2;
            color: var(--nature-dark);
            margin-bottom: 0.75rem;
        }

        .subtitle {
            font-family: 'Source Serif 4', Georgia, serif;
            font-size: 1.25rem;
            font-weight: 400;
            color: var(--nature-grey);
            margin-bottom: 1rem;
        }

        .tagline {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--nature-dark);
            margin-bottom: 1.5rem;
        }

        .author-info {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 0.9rem;
            color: var(--nature-grey);
        }

        .author-info .name {
            font-weight: 600;
            color: var(--nature-dark);
        }

        .version-date {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 0.8rem;
            color: var(--nature-grey);
            margin-top: 0.5rem;
        }

        /* Section Headings */
        h2 {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 1.4rem;
            font-weight: 700;
            color: var(--nature-dark);
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--nature-border);
        }

        h3 {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 1.15rem;
            font-weight: 600;
            color: var(--nature-dark);
            margin-top: 1.75rem;
            margin-bottom: 0.75rem;
        }

        h4 {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 1rem;
            font-weight: 600;
            color: var(--nature-dark);
            margin-top: 1.25rem;
            margin-bottom: 0.5rem;
        }

        /* Paragraphs */
        p {
            margin-bottom: 1rem;
            text-align: justify;
            hyphens: auto;
        }

        /* Core Claim Box */
        .core-claim {
            background: linear-gradient(135deg, #fafafa 0%, #f0f0f0 100%);
            border-left: 4px solid var(--nature-red);
            padding: 1.5rem 1.75rem;
            margin: 2rem 0;
            font-size: 1.05rem;
            font-weight: 400;
            border-radius: 0 4px 4px 0;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }

        .core-claim strong {
            color: var(--nature-red);
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            display: block;
            margin-bottom: 0.5rem;
        }

        /* Equation Display */
        .equation-box {
            background: linear-gradient(to bottom, #fafafa 0%, #f5f5f5 100%);
            border: 1px solid var(--nature-border);
            border-radius: 6px;
            padding: 2rem 1.5rem;
            margin: 2rem 0;
            text-align: center;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        }

        .equation-box .equation {
            font-size: 1.6rem;
            margin-bottom: 0.75rem;
            line-height: 1.8;
        }

        .equation-box .equation-label {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 0.85rem;
            color: var(--nature-grey);
            font-style: italic;
            margin-top: 0.5rem;
        }

        /* Inline equations */
        .MathJax {
            font-size: 1.05em !important;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.75rem 0;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        thead {
            background: linear-gradient(to bottom, #f8f9fa 0%, #f0f0f0 100%);
        }

        th {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-weight: 600;
            text-align: left;
            padding: 0.85rem 0.75rem;
            border-bottom: 2px solid var(--nature-dark);
            color: var(--nature-dark);
        }

        td {
            padding: 0.75rem;
            border-bottom: 1px solid var(--nature-border);
            vertical-align: top;
        }

        tr:hover {
            background: rgba(0,0,0,0.015);
        }

        /* First column styling */
        td:first-child {
            font-weight: 500;
        }

        /* Lists */
        ul, ol {
            margin: 1rem 0 1rem 1.5rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        /* Blockquotes */
        blockquote {
            border-left: 3px solid var(--nature-red);
            padding-left: 1.25rem;
            margin: 1.5rem 0;
            font-style: italic;
            color: var(--nature-grey);
        }

        /* Key findings highlight */
        .key-findings {
            background: linear-gradient(to right, #f8f9fa 0%, #ffffff 100%);
            border: 1px solid #e9ecef;
            border-left: 3px solid var(--nature-red);
            border-radius: 0 4px 4px 0;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .key-findings h4 {
            color: var(--nature-red);
            margin-top: 0;
            margin-bottom: 1rem;
            font-size: 1rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }

        .key-findings ul {
            margin: 0;
        }

        .key-findings li {
            margin-bottom: 0.75rem;
            line-height: 1.6;
        }

        .key-findings li:last-child {
            margin-bottom: 0;
        }

        /* Abstract box */
        .abstract {
            background: #fafafa;
            padding: 2rem;
            margin: 2rem 0;
            border-radius: 6px;
            border: 1px solid #e9ecef;
        }

        .abstract h2 {
            margin-top: 0;
            border-bottom: 2px solid var(--nature-red);
            padding-bottom: 0.5rem;
            margin-bottom: 1.25rem;
        }

        .abstract p:last-of-type {
            margin-bottom: 0;
        }

        /* Falsification table */
        .falsification-table {
            font-size: 0.85rem;
        }

        .falsification-table th {
            font-size: 0.8rem;
        }

        .status-holds {
            color: #28a745;
            font-weight: 600;
        }

        .status-untested {
            color: #6c757d;
        }

        .status-open {
            color: #ffc107;
            font-weight: 600;
        }

        /* Caveat boxes */
        .caveat {
            background: #fff3cd;
            border: 1px solid #ffc107;
            border-radius: 4px;
            padding: 1rem;
            margin: 1rem 0;
            font-size: 0.9rem;
        }

        .caveat strong {
            color: #856404;
        }

        /* Important box */
        .important {
            background: #e7f3ff;
            border: 1px solid #b6d4fe;
            border-radius: 4px;
            padding: 1rem;
            margin: 1rem 0;
        }

        /* References */
        .references {
            font-size: 0.85rem;
        }

        .references p {
            margin-bottom: 0.75rem;
            padding-left: 2rem;
            text-indent: -2rem;
        }

        /* Footer */
        footer {
            margin-top: 4rem;
            padding: 2rem 0;
            border-top: 3px solid var(--nature-red);
            font-size: 0.85rem;
            color: var(--nature-grey);
            text-align: center;
            background: linear-gradient(to bottom, #fafafa 0%, #ffffff 100%);
        }

        footer p {
            margin-bottom: 0.5rem;
            text-align: center;
        }

        footer p:last-child {
            margin-bottom: 0;
            margin-top: 1rem;
            font-style: italic;
            color: var(--nature-dark);
        }

        /* Code blocks for equations */
        code {
            font-family: 'SF Mono', Consolas, 'Liberation Mono', Menlo, monospace;
            font-size: 0.9em;
            background: var(--nature-light-grey);
            padding: 0.15em 0.4em;
            border-radius: 3px;
        }

        /* Figure styles */
        figure {
            margin: 2rem 0;
            padding: 0;
            text-align: center;
            page-break-inside: avoid;
            break-inside: avoid;
        }

        figure img {
            max-width: 100%;
            height: auto;
            border: 1px solid var(--nature-border);
            border-radius: 4px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        figcaption {
            font-family: 'Source Sans 3', Helvetica, Arial, sans-serif;
            font-size: 0.85rem;
            color: var(--nature-grey);
            margin-top: 0.75rem;
            text-align: left;
            line-height: 1.5;
            padding: 0 1rem;
        }

        figcaption strong {
            color: var(--nature-dark);
        }

        /* Print styles */
        @page {
            size: A4;
            margin: 1.5cm 1.8cm 2cm 1.8cm;
        }

        @media print {
            html {
                -webkit-print-color-adjust: exact;
                print-color-adjust: exact;
            }

            body {
                max-width: none;
                padding: 0;
                margin: 0;
                font-size: 9.5pt;
                line-height: 1.5;
            }

            /* Compact header for print */
            header {
                border-bottom-width: 2px;
                padding-bottom: 0.8em;
                margin-bottom: 0.8em;
            }

            header h1 {
                font-size: 1.6rem;
                margin-bottom: 0.3em;
            }

            header .paper-type {
                font-size: 0.65rem;
                margin-bottom: 0.3em;
            }

            header .subtitle {
                font-size: 1rem;
                margin-bottom: 0.4em;
            }

            header .tagline {
                font-size: 0.8rem;
                margin-bottom: 0.6em;
            }

            header .author-info {
                font-size: 0.8rem;
            }

            header .version-date {
                font-size: 0.7rem;
                margin-top: 0.3em;
            }

            /* Core claim - compact */
            .core-claim {
                padding: 0.8em 1em;
                margin: 0.8em 0;
                font-size: 0.95em;
            }

            .core-claim strong {
                font-size: 0.8rem;
                margin-bottom: 0.3em;
            }

            /* Headings - MUST stay with following content */
            h2 {
                font-size: 1.2rem;
                margin-top: 1.2em;
                margin-bottom: 0.5em;
                page-break-after: avoid !important;
                break-after: avoid !important;
            }

            h3 {
                font-size: 1rem;
                margin-top: 1em;
                margin-bottom: 0.4em;
                page-break-after: avoid !important;
                break-after: avoid !important;
            }

            h4 {
                font-size: 0.9rem;
                margin-top: 0.8em;
                margin-bottom: 0.3em;
                page-break-after: avoid !important;
                break-after: avoid !important;
            }

            /* Content after headings must not break before */
            h2 + *, h3 + *, h4 + * {
                page-break-before: avoid !important;
                break-before: avoid !important;
            }

            /* Second element after heading also avoid break */
            h2 + * + *, h3 + * + *, h4 + * + * {
                page-break-before: avoid !important;
                break-before: avoid !important;
            }

            p {
                orphans: 3;
                widows: 3;
                margin-bottom: 0.5em;
            }

            /* Tables - allow breaking but keep header with first row */
            table {
                margin-top: 0.5em;
                margin-bottom: 0.5em;
                font-size: 8.5pt;
            }

            thead {
                display: table-header-group;
            }

            table th, table td {
                padding: 3px 5px;
            }

            /* Keep table rows together */
            tr {
                page-break-inside: avoid;
                break-inside: avoid;
            }

            /* Small boxes - only avoid breaks if they're small */
            .equation-box {
                page-break-inside: avoid;
                break-inside: avoid;
                padding: 0.6em;
                margin: 0.5em 0;
            }

            .equation-box .equation {
                font-size: 1.1em;
            }

            .key-findings {
                padding: 0.8em;
                margin: 0.5em 0;
                /* Allow breaking if needed */
            }

            .caveat, .important {
                margin: 0.5em 0;
                padding: 0.6em;
                /* Allow breaking if needed */
            }

            /* Lists - allow breaking */
            ul, ol {
                margin: 0.4em 0 0.4em 1.2em;
            }

            li {
                margin-bottom: 0.3em;
            }

            /* Abstract - allow breaking */
            .abstract {
                padding: 1em;
                margin: 0.8em 0;
            }

            .abstract h2 {
                margin-top: 0;
                margin-bottom: 0.6em;
            }

            /* Figures - larger and clearer */
            figure {
                page-break-inside: avoid;
                break-inside: avoid;
                margin: 1.2em 0;
                padding: 0.3em 0;
            }

            figure img {
                max-height: 520px;
                width: auto;
                max-width: 100%;
                display: block;
                margin: 0 auto;
                border: none !important;
                box-shadow: none !important;
                border-radius: 0 !important;
            }

            figcaption {
                font-size: 8.5pt;
                margin-top: 0.8em;
                padding: 0 0.5em;
                line-height: 1.45;
            }

            /* Hide screen-only elements */
            .no-print {
                display: none !important;
            }

            /* Footer styling for print */
            footer {
                margin-top: 1.5em;
                padding-top: 0.8em;
                border-top-width: 2px;
                font-size: 8pt;
            }

            footer p {
                margin-bottom: 0.3em;
            }
        }

        /* Responsive */
        @media (max-width: 600px) {
            body {
                padding: 1rem;
            }

            h1 {
                font-size: 1.75rem;
            }

            table {
                font-size: 0.8rem;
            }

            th, td {
                padding: 0.4rem 0.25rem;
            }
        }
    </style>
</head>
<body>

<header>
    <div class="paper-type">White Paper III</div>
    <h1>EASTWOOD'S ARC PRINCIPLE</h1>
    <div class="subtitle">Cross-Domain Unification of Recursive Amplification Across AI, Quantum Computing, and Physics</div>
    <div class="tagline">Why AI, Quantum Computers, and Time Crystals All Follow the Same Mathematical Pattern</div>
    <div class="author-info">
        <span class="name">Michael Darius Eastwood</span><br>
        <em>Author, Infinite Architects: Intelligence, Recursion, and the Creation of Everything</em>
    </div>
    <div class="version-date">Version 6.1 | 9 February 2026</div>
</header>

<div class="core-claim">
    <strong>THE CORE CLAIM IN ONE SENTENCE:</strong> The way a system processes information recursively (whether it builds on its own outputs or merely averages independent attempts) determines whether its capabilities compound exponentially or stagnate.
</div>

<p>This paper presents evidence that this principle applies across AI, quantum computing, classical physics, and possibly neuroscience, and provides ten specific ways to prove us wrong.</p>

<div class="abstract">
<h2>ABSTRACT</h2>

<p>Between December 2024 and February 2026, four independent research teams (working on quantum computers, AI language models, acoustic physics, and consciousness) converged on the same architectural insight without any knowledge of each other's work. All four discovered that recursive self-correction, operating on structured asymmetry, produces super-linear capability gains.</p>

<p>We formalise this pattern as <strong>Eastwood's Principle of Recursive Amplification</strong>, the <strong>ARC Principle</strong> (Artificial Recursive Creation):</p>

<div class="equation-box">
    <div class="equation">$$ U = I \times R^{\alpha} $$</div>
    <div class="equation-label">The ARC Equation</div>
</div>

<p>where $U$ is effective capability, $I$ is base potential (the "frozen disorder" or structured asymmetry enabling the system to function), $R$ is recursive depth (how many self-referential cycles the system performs), and $\alpha$ is the scaling exponent that determines whether returns compound ($\alpha > 1$) or diminish ($\alpha < 1$).</p>

<p>We derive the power-law form from first principles and show that $\alpha = 1/(1-\beta)$, where $\beta$ measures how much accumulated capability improves subsequent processing steps. This transforms $\alpha$ from a fitted constant into a derived quantity with physical meaning and testable predictions.</p>

<div class="key-findings">
<h4>Key Empirical Findings</h4>
<ul>
    <li>DeepSeek R1 achieves $\alpha \approx 1.3$&ndash;$2.2$ for sequential reasoning vs $\alpha \approx 0$ for parallel sampling</li>
    <li>Google's Willow quantum chip shows $\Lambda = 2.14$ error suppression through recursive correction</li>
    <li>NYU's acoustic time crystal requires "frozen disorder" + recursive feedback: the exact structural prerequisites the principle predicts</li>
</ul>
</div>

<p>We issue a <strong>Global Scaling Challenge</strong> with a standardised measurement protocol. We specify <strong>ten falsification criteria</strong>: concrete conditions that would refute the hypothesis. We explicitly acknowledge what we do NOT claim, including the critical point that numerical similarities across domains may be coincidental.</p>

<p><strong>Critical prediction:</strong> The framework predicts a distinct <strong>phase transition</strong> at critical depth $R^*$, where scaling switches from linear ($U \propto R$) to power-law ($U \propto R^{\alpha}$). This linear-to-superlinear crossover is a unique signature of recursive amplification that distinguishes it from simple redundancy, and is directly testable.</p>

<p>If validated, the framework has immediate implications for AI safety: alignment properties embedded in the recursive process scale with capability, while external constraints do not.</p>

<p><strong>Keywords:</strong> scaling laws, recursive intelligence, test-time compute, error suppression, AI alignment, chain-of-thought reasoning, time crystals, cross-domain validation</p>
</div>

<figure>
    <img src="figures/fig1_equation.png" alt="The ARC Equation: U = I × R^α">
    <figcaption><strong>Figure 1 | The ARC Equation.</strong> Effective capability (U) equals base potential (I) multiplied by recursive depth (R) raised to the scaling exponent (α). When α > 1, returns compound with each recursive cycle. The exponent α is derived from first principles as α = 1/(1-β), where β measures self-referential coupling.</figcaption>
</figure>

<h2>FOR THE GENERAL READER: WHAT THIS MEANS</h2>

<p>Imagine you're solving a difficult problem. You have two strategies:</p>

<p><strong>Strategy A (Sequential):</strong> Think through the problem step by step. Each step builds on what you figured out in the previous step. If you notice an error, you go back and fix it.</p>

<p><strong>Strategy B (Parallel):</strong> Ask ten different people to solve the problem independently, then take a vote on the answer.</p>

<p>Which strategy works better for hard problems?</p>

<p>Our research (and converging evidence from quantum physics, AI, and materials science) suggests that Strategy A doesn't just work <em>better</em>. It works <em>exponentially</em> better. Each additional step of careful, self-correcting reasoning doesn't add a fixed amount of capability. It <em>multiplies</em> your capability by a factor.</p>

<p>Meanwhile, Strategy B (just throwing more parallel attempts at the problem) shows diminishing returns. Adding more parallel workers doesn't help much if they can't learn from each other's mistakes.</p>

<h3>Why Does This Matter?</h3>

<ol>
    <li><strong>For AI development:</strong> It tells us <em>how</em> to build more capable AI systems (sequential self-correction) rather than just making them bigger.</li>
    <li><strong>For AI safety:</strong> If capabilities compound through recursion, then alignment (the AI's values and goals) must be embedded <em>in</em> the recursive process, not bolted on afterwards. External rules can't keep up with exponentially growing capabilities.</li>
    <li><strong>For science:</strong> The same mathematical pattern appearing independently in quantum physics, AI, and classical acoustics suggests we may have discovered something fundamental about how order emerges from complexity.</li>
</ol>

<p><strong>The most important part:</strong> We could be wrong. That's why we've specified ten concrete ways to prove us wrong. Science advances by testing predictions, not by making unfalsifiable claims. If our predictions fail, we'll have learned something valuable. If they hold, we'll have identified a principle that could reshape how we think about intelligence, computation, and the physics of order.</p>

<h2>1. INTRODUCTION</h2>

<h3>1.1 The Puzzle: Why Did Four Teams Find the Same Thing?</h3>

<p>Between December 2024 and February 2026, four research programmes achieved breakthroughs that share a striking structural commonality:</p>

<p><strong>8 December 2024: The ARC Principle (Artificial Recursive Creation).</strong> The theoretical framework presented in this paper was articulated in <em>Infinite Architects</em> (Eastwood, 2024), predicting that recursive self-correction operating on structured asymmetry would produce super-linear capability gains across physical systems. The manuscript was transmitted via email on 8 December 2024 (DKIM-verified timestamp available upon request).</p>

<p><strong>9 December 2024: Google Willow.</strong> Quantum researchers demonstrated exponential error suppression through recursive quantum error correction, achieving a suppression factor of $\Lambda = 2.14 \pm 0.02$. The Willow paper was under <em>Nature</em> review and publicly inaccessible at the time the ARC framework was articulated.</p>

<p><strong>January 2025: DeepSeek R1.</strong> AI researchers showed that sequential chain-of-thought reasoning yields capability gains that compound with depth ($\alpha \approx 1.3$&ndash;$2.2$), while parallel sampling shows near-zero returns ($\alpha \approx 0$).</p>

<p><strong>February 2026: NYU Acoustic Time Crystals.</strong> Physicists created the first continuous classical time crystal, demonstrating that spontaneous temporal order emerges when "frozen disorder" is combined with "non-reciprocal feedback loops."</p>

<p>These teams share no common research heritage. The theoretical prediction came from information theory. Google worked with cryogenic quantum hardware. DeepSeek trained language models. NYU levitated foam beads in sound waves. Yet all four converged on the same insight: <strong>recursive self-correction, operating on structured asymmetry, produces super-linear gains.</strong></p>

<p>The convergence itself is evidence. When independent investigators discover the same mathematical relationship without knowledge of each other's work, and when the theoretical prediction <em>precedes</em> the experimental confirmations, it suggests they are describing something real.</p>

<h3>1.2 What This Paper Does NOT Claim</h3>

<p>Before proceeding, we explicitly state what this paper does NOT claim:</p>

<table>
    <thead>
        <tr>
            <th>We do NOT claim:</th>
            <th>What we actually claim:</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>That $\Lambda = 2.14$ and $\alpha \approx 2.2$ are the "same number"</td>
            <td>They are mathematically distinct quantities that both indicate super-linear recursive gains</td>
        </tr>
        <tr>
            <td>That time crystals have been measured to follow $U = I \times R^{\alpha}$</td>
            <td>The structural prerequisites match; quantitative measurement is a priority for future work</td>
        </tr>
        <tr>
            <td>That the framework is proven</td>
            <td>It is a testable hypothesis with specific falsification criteria</td>
        </tr>
        <tr>
            <td>That consciousness "is" recursion</td>
            <td>Recurrent processing is architecturally important; the connection is consistent but not proven</td>
        </tr>
        <tr>
            <td>That we have discovered a "Theory of Everything"</td>
            <td>We propose a scaling law, like Kleiber's Law, that describes a pattern</td>
        </tr>
        <tr>
            <td>That small sample sizes don't matter</td>
            <td>They do; we explicitly acknowledge all statistical limitations</td>
        </tr>
        <tr>
            <td>That cross-domain numerical coincidences prove anything</td>
            <td>They suggest further investigation; the structural parallels are the meaningful observation</td>
        </tr>
    </tbody>
</table>

<p>This paper presents a <strong>candidate principle requiring validation</strong>, not an established law.</p>

<h3>1.3 Contributions</h3>

<p>We make five contributions:</p>

<ol>
    <li><strong>Mathematical Framework:</strong> We derive $U = I \times R^{\alpha}$ from first principles and show that $\alpha = 1/(1-\beta)$, transforming the exponent from a fitted constant into a derived quantity.</li>
    <li><strong>Evidence Synthesis:</strong> We integrate findings from AI, quantum physics, condensed matter, and neuroscience, carefully distinguishing quantitative validation from structural analogy.</li>
    <li><strong>The Global Challenge:</strong> We propose a standardised protocol for measuring $\alpha$, including mandatory comparison against alternative functional forms (exponential, logarithmic).</li>
    <li><strong>Ten Falsification Criteria:</strong> We specify concrete conditions that would refute the hypothesis.</li>
    <li><strong>Safety Implications (Conditional):</strong> <em>If</em> the framework is correct, embedded values scale with capability while external constraints do not.</li>
</ol>

<h2>2. THE FRAMEWORK</h2>

<h3>2.1 The Equation</h3>

<p><strong>Eastwood's Principle of Recursive Amplification:</strong></p>

<div class="equation-box">
    <div class="equation">$$ U = I \times R^{\alpha} $$</div>
    <div class="equation-label">Effective capability = Base potential &times; Recursive depth<sup>&alpha;</sup></div>
</div>

<p><strong>In plain language:</strong> Your effective capability ($U$) equals your starting potential ($I$) multiplied by your recursive depth ($R$) raised to a power ($\alpha$) that depends on how well each step builds on the previous one.</p>

<figure>
    <img src="figures/fig2_scaling.png" alt="Scaling Comparison on Log-Log Axes">
    <figcaption><strong>Figure 2 | Scaling Comparison.</strong> Log-log plot showing different scaling regimes. Power law U = R^α appears as a straight line with slope α. Sequential recursion (α > 1) shows super-linear growth; parallel sampling (α < 1) shows diminishing returns. The ARC Principle predicts α_sequential > 1 > α_parallel.</figcaption>
</figure>

<h3>2.2 What Each Variable Means</h3>

<h4>$U$: Effective Capability</h4>

<p>What the system actually achieves. Measured differently in each domain:</p>
<ul>
    <li>AI: Benchmark accuracy on standardised tests</li>
    <li>Quantum: Logical qubit fidelity (how error-free the computation is)</li>
    <li>Physics: Temporal stability of the time crystal</li>
    <li>Biology: Metabolic efficiency or cognitive performance</li>
</ul>

<h4>$I$: Base Potential ("Frozen Disorder")</h4>

<p><strong>Thermodynamic definition:</strong> Natural systems tend towards maximum entropy (equilibrium/uniformity). "Artificial" systems maintain low-entropy states far from equilibrium through the injection of work. The parameter $I$ measures <em>how far from maximum entropy</em> the system starts.</p>

<p>The NYU time crystal confirms this: when beads are uniform (maximum entropy distribution), the system remains static. Only when "frozen disorder" (a low-entropy, engineered state) is introduced does the system break time-translation symmetry. Order requires <em>designed disorder</em>: a specific pattern of asymmetry that enables work extraction from the environment.</p>

<table>
    <thead>
        <tr>
            <th>Domain</th>
            <th>What $I$ measures</th>
            <th>Physical meaning</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>AI</td>
            <td>Single-pass accuracy without reasoning</td>
            <td>How much "prior knowledge" the model has</td>
        </tr>
        <tr>
            <td>Quantum</td>
            <td>Raw qubit quality ($1 - $ error rate)</td>
            <td>Distance from maximum entropy</td>
        </tr>
        <tr>
            <td>Physics</td>
            <td>Variance in bead sizes</td>
            <td>Asymmetry enabling non-reciprocal forces</td>
        </tr>
        <tr>
            <td>Biology</td>
            <td>Initial learning rate</td>
            <td>Sensitivity gradient</td>
        </tr>
    </tbody>
</table>

<p><strong>The key insight: Constraint enables competence.</strong> Without structured asymmetry, no work can be extracted. The time crystal proves this: uniform beads = no crystal.</p>

<h4>$R$: Recursive Depth</h4>

<p>How many self-referential cycles the system performs. The output of cycle $n$ becomes the input for cycle $n+1$.</p>

<table>
    <thead>
        <tr>
            <th>Domain</th>
            <th>One unit of $R$</th>
            <th>How it's counted</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>AI</td>
            <td>One reasoning step</td>
            <td>Token count or revision cycle</td>
        </tr>
        <tr>
            <td>Quantum</td>
            <td>One error-correction cycle</td>
            <td>Code distance increment</td>
        </tr>
        <tr>
            <td>Physics</td>
            <td>One oscillation period</td>
            <td>Frequency analysis</td>
        </tr>
        <tr>
            <td>Biology</td>
            <td>One feedback cycle</td>
            <td>Generation or learning iteration</td>
        </tr>
    </tbody>
</table>

<p><strong>Critical requirement:</strong> For $\alpha > 1$, recursion must be <em>sequential</em>. Each step must build on the previous one. Parallel processing (independent attempts averaged together) cannot correct errors, only average over them.</p>

<h4>$\alpha$: The Scaling Exponent</h4>

<p>This determines everything:</p>

<table>
    <thead>
        <tr>
            <th>$\alpha$ value</th>
            <th>What happens</th>
            <th>Example</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>$\alpha < 1$</td>
            <td>Diminishing returns</td>
            <td>Parallel voting: more samples help less and less</td>
        </tr>
        <tr>
            <td>$\alpha = 1$</td>
            <td>Linear returns</td>
            <td>Each step adds a fixed amount</td>
        </tr>
        <tr>
            <td>$\alpha > 1$</td>
            <td>Compounding returns</td>
            <td>Each step multiplies capability</td>
        </tr>
    </tbody>
</table>

<p><strong>Our core prediction:</strong> $\alpha_{\text{sequential}} > 1 > \alpha_{\text{parallel}}$</p>

<h3>2.3 Deriving $\alpha$ from First Principles</h3>

<p>This is our central theoretical contribution. Without this derivation, $\alpha$ is just a number we fit to data. With it, $\alpha$ becomes a predictable quantity.</p>

<h4>The Key Insight</h4>

<p>How much does your accumulated knowledge help your next step?</p>

<p>Define $\beta$ as the "self-referential coupling": how much each new step benefits from everything you've already figured out.</p>

<p>If each step is independent ($\beta = 0$), you get linear scaling ($\alpha = 1$).<br>
If each step fully leverages all prior work ($\beta \to 1$), scaling explodes.</p>

<h4>The Mathematics</h4>

<p>The marginal capability gained at step $r$ depends on accumulated capability:</p>

<div class="equation-box">
    <div class="equation">$$ \frac{dQ}{dr} = a \times Q^{\beta} $$</div>
</div>

<p><strong>Why this form?</strong> This differential equation models <em>cumulative advantage</em> (also called preferential attachment): the probability of correcting an error or discovering a solution is proportional to the system's current capability. This is mechanistically consistent with "reservoir computing" in neural networks and "syndrome history" in quantum error correction, where past success increases the probability of future success. It is the mathematical signature of "the rich get richer", but for information processing.</p>

<p>Solving this differential equation (details in Appendix A) yields:</p>

<div class="equation-box">
    <div class="equation">$$ \alpha = \frac{1}{1 - \beta} $$</div>
    <div class="equation-label">The $\beta$-derivation</div>
</div>

<h4>What This Means</h4>

<table>
    <thead>
        <tr>
            <th>$\beta$ (coupling)</th>
            <th>$\alpha$ (exponent)</th>
            <th>Interpretation</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0</td>
            <td>1</td>
            <td>Independent steps &rarr; linear scaling</td>
        </tr>
        <tr>
            <td>0.25</td>
            <td>1.33</td>
            <td>Weak coupling &rarr; mild super-linear</td>
        </tr>
        <tr>
            <td>0.50</td>
            <td>2.00</td>
            <td>Moderate coupling &rarr; quadratic scaling</td>
        </tr>
        <tr>
            <td>0.67</td>
            <td>3.00</td>
            <td>Strong coupling &rarr; cubic scaling</td>
        </tr>
    </tbody>
</table>

<p><strong>Novel Prediction:</strong> As AI systems develop richer self-correction (critique-revise loops, hierarchical reasoning), $\beta$ should increase and $\alpha$ should approach 2. This is specific, measurable, and falsifiable.</p>

<figure>
    <img src="figures/fig3_beta_alpha.png" alt="The β-α Relationship">
    <figcaption><strong>Figure 3 | The β–α Relationship.</strong> The scaling exponent α is derived from the self-referential coupling β via α = 1/(1-β). As β approaches 1 (perfect feedback efficiency), α diverges towards infinity. The observed range of α ≈ 1.3–2.2 in AI systems corresponds to β ≈ 0.25–0.55, indicating moderate self-referential coupling in current architectures.</figcaption>
</figure>

<h3>2.4 Why This Matters: The Alignment Theorem</h3>

<p><strong>If</strong> the ARC Principle is correct, it has profound implications for AI safety.</p>

<p><strong>Setup:</strong> Capability scales as $C = C_0 \times R^{\alpha}$ where $\alpha > 1$.</p>

<h4>Case 1: External Constraints (Rules, Firewalls, RLHF)</h4>

<p>These don't participate in recursive reasoning. They're applied <em>after</em> computation. Call their scaling exponent $\alpha_{\text{align}} \approx 0$.</p>

<p>Safety ratio: $S = \text{Alignment}/\text{Capability} \propto R^{-\alpha} \to 0$ as $R \to \infty$</p>

<p><strong>External constraints become infinitely weak relative to capability.</strong></p>

<h4>Case 2: Embedded Values (Ethics in the Reasoning Process)</h4>

<p>If the AI's values participate in chain-of-thought reasoning, they benefit from the same compounding. $\alpha_{\text{align}} \approx \alpha$.</p>

<p>Safety ratio: $S \propto R^0 = \text{constant}$</p>

<p><strong>Embedded values maintain constant proportion with capability.</strong></p>

<h4>The Implication</h4>

<p>AI systems should be <em>raised with values</em>, not <em>caged with rules</em>. Alignment must be part of the recursive architecture, not external to it. This theorem assumes alignment properties can meaningfully "participate" in recursive reasoning, an assumption that itself requires empirical validation.</p>

<div class="caveat">
<strong>CAVEAT:</strong> This is a conditional theorem. If the base framework fails validation, the safety implications are void. This is not a substitute for empirical AI safety research.
</div>

<figure>
    <img src="figures/fig7_alignment.png" alt="The Alignment Theorem">
    <figcaption><strong>Figure 4 | The Alignment Theorem.</strong> External constraints (rules, firewalls) scale with α ≈ 0, becoming infinitely weak relative to capability as R increases. Embedded values that participate in recursive reasoning scale with α ≈ α_capability, maintaining constant proportion. AI systems should be raised with values, not caged with rules.</figcaption>
</figure>

<h2>3. THE EVIDENCE</h2>

<h3>3.1 Overview</h3>

<table>
    <thead>
        <tr>
            <th>Domain</th>
            <th>System</th>
            <th>Finding</th>
            <th>$\alpha$/$\Lambda$</th>
            <th>Confidence</th>
            <th>Status</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>AI</td>
            <td>DeepSeek R1</td>
            <td>Sequential &gt;&gt; Parallel</td>
            <td>$\alpha \approx 1.3$&ndash;$2.2$</td>
            <td>Low (small n)</td>
            <td>Preliminary</td>
        </tr>
        <tr>
            <td>Quantum</td>
            <td>Google Willow</td>
            <td>Exponential error suppression</td>
            <td>$\Lambda = 2.14$</td>
            <td>High</td>
            <td>Published</td>
        </tr>
        <tr>
            <td>Physics</td>
            <td>NYU Time Crystal</td>
            <td>Frozen disorder + feedback &rarr; order</td>
            <td>Not measured</td>
            <td>N/A</td>
            <td>Structural</td>
        </tr>
        <tr>
            <td>Biology</td>
            <td>Kleiber's Law</td>
            <td>Fractal recursive networks &rarr; $M^{0.75}$</td>
            <td>$\alpha_{\text{eff}} \approx 1.33$&dagger;</td>
            <td>Low</td>
            <td>Suggestive</td>
        </tr>
        <tr>
            <td>Neuro</td>
            <td>COGITATE</td>
            <td>Recurrence architecturally central</td>
            <td>N/A</td>
            <td>N/A</td>
            <td>Consistent</td>
        </tr>
    </tbody>
</table>

<p>&dagger;Derived from 3/4 exponent under fractal network interpretation; contested.</p>

<figure>
    <img src="figures/fig4_domains.png" alt="Four Domains of Evidence">
    <figcaption><strong>Figure 5 | Four Independent Domains of Evidence.</strong> The ARC Principle emerged from convergent findings across AI (DeepSeek R1), quantum computing (Google Willow), classical physics (NYU time crystals), and neuroscience (COGITATE). These teams share no common research heritage, yet all discovered that recursive self-correction on structured asymmetry produces super-linear gains.</figcaption>
</figure>

<div class="important">
<strong>Critical note:</strong> $\Lambda$ and $\alpha$ are <em>different mathematical quantities</em>. Both indicate super-linear recursive gains, but they cannot be numerically compared.
</div>

<h3>3.2 AI: DeepSeek R1 (January 2025)</h3>

<p><strong>Source:</strong> DeepSeek-R1 Technical Report (20 January 2025), arXiv:2501.12948. Independent validation in "The Sequential Edge" by Sharma &amp; Chopra (November 2025), arXiv:2511.02309.</p>

<p><strong>What they did:</strong> Compared sequential reasoning (each step builds on the last) vs parallel sampling (independent attempts, majority vote).</p>

<p><strong>What they found:</strong></p>

<table>
    <thead>
        <tr>
            <th>Method</th>
            <th>Tokens used</th>
            <th>Accuracy</th>
            <th>Estimated $\alpha$</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Sequential (short)</td>
            <td>12,065</td>
            <td>52%</td>
            <td>N/A</td>
        </tr>
        <tr>
            <td>Sequential (long)</td>
            <td>23,436</td>
            <td>78%</td>
            <td>~1.34</td>
        </tr>
        <tr>
            <td>Parallel (majority)</td>
            <td>1,101</td>
            <td>53%</td>
            <td>~0.1</td>
        </tr>
    </tbody>
</table>

<p><strong>Error Suppression Data:</strong> Sequential error rates dropped from 48% at 280 reasoning tokens to 22% at 576 tokens &ndash; a fivefold reduction in error probability. At matched compute, sequential processing (78% accuracy) outperformed parallel processing (53% accuracy) by 25 percentage points despite using comparable total tokens.</p>

<p><strong>Key result:</strong> Sequential reasoning at 12,065 tokens (52%) already matches parallel sampling at 1,101 tokens (53%). At 23,436 tokens it reaches 78%, a 25-percentage-point improvement. Doubling sequential depth nearly doubled performance; tripling parallel samples added nothing. The <em>form</em> of recursion, not just quantity, determines capability.</p>

<p><strong>Independent validation:</strong> Sharma &amp; Chopra (2025) confirmed across 45 configurations: sequential wins 95.6% of the time. Their analysis found $\alpha \approx 2.2$ (95% CI: 1.5–3.0) for sequential recursion.</p>

<div class="caveat">
<strong>Statistical caveat:</strong> The $\alpha \approx 1.34$ estimate uses only two data points. The broader $\alpha \approx 2.2$ estimate (95% CI: 1.5&ndash;3.0) uses 12 problems, which is still small. These are <em>preliminary indicators</em>, not established constants. The convergence of both estimates towards $\alpha \approx 2$ is noteworthy but requires replication.
</div>

<figure>
    <img src="figures/fig9_deepseek.png" alt="DeepSeek R1 Sequential vs Parallel Scaling">
    <figcaption><strong>Figure 6 | Sequential vs Parallel Scaling in DeepSeek R1.</strong> Sequential reasoning (blue) shows super-linear scaling (α ≈ 1.3–2.2), while parallel sampling (red) shows near-zero returns (α ≈ 0.1). At matched compute, sequential processing achieves 78% accuracy compared to 53% for parallel. A 25-percentage-point advantage. The form of recursion, not just quantity, determines capability.</figcaption>
</figure>

<h3>3.3 Quantum: Google Willow (December 2024)</h3>

<p><strong>What they did:</strong> Implemented recursive quantum error correction on superconducting qubits.</p>

<p><strong>What they found:</strong> Error suppression factor $\Lambda = 2.14 \pm 0.02$. Errors decrease exponentially with each correction cycle: $\varepsilon \propto \exp(-\Lambda \times d)$.</p>

<p><strong>Why it matters:</strong> This is threshold behaviour. Beyond a critical point, recursive correction outperforms its theoretical baseline. Each cycle acts as a self-referential correction step.</p>

<div class="important">
<strong>IMPORTANT:</strong> $\Lambda$ and $\alpha$ are mathematically distinct:
<ul>
    <li>$\Lambda$ is an <em>exponential decay rate</em> (how fast errors vanish)</li>
    <li>$\alpha$ is a <em>power-law exponent</em> (how fast capability grows)</li>
</ul>
<p>The numerical similarity (2.14 vs ~2.2) may be coincidental. What they share is <em>threshold behaviour</em>. Both indicate regimes where recursive processing outperforms baselines. The structural parallel is meaningful; the numerical coincidence is not evidence.</p>
</div>

<h3>3.4 Physics: NYU Acoustic Time Crystals (February 2026)</h3>

<p><strong>Source:</strong> Morrell, M., Elliott, L., &amp; Grier, D.G. (6 February 2026). "Nonreciprocal wave-mediated interactions power a classical time crystal." <em>Physical Review Letters</em>, 136, 057201.</p>

<p><strong>What they did:</strong> Levitated millimetre-scale polystyrene foam beads in an acoustic standing wave at 160 Hz and observed spontaneous temporal order.</p>

<p><strong>What they found:</strong> The system requires two components:</p>
<ol>
    <li><strong>Frozen disorder ($I$):</strong> Beads of varied sizes creating asymmetric scattering. Larger particles scatter sound waves more effectively, influencing small beads to a greater degree than vice versa.</li>
    <li><strong>Non-reciprocal feedback ($R$):</strong> Sound waves where $F_{AB} \neq -F_{BA}$. This violates Newton's Third Law locally, enabling sustained oscillation.</li>
</ol>

<p>When both present &rarr; spontaneous oscillation (temporal order from spatial chaos)<br>
When beads are uniform &rarr; "strange effects vanish" (no crystal forms)</p>

<p><strong>Why it matters:</strong> This is the ARC Principle made visible. Constraint ($I$) enables competence. Feedback ($R$) compounds it. The "Intelligence" in the ARC equation maps directly to the "frozen disorder" &ndash; the specific distribution of unequal bead sizes. Without this asymmetry, forces balance and the rhythmic "ticking" of the time crystal vanishes.</p>

<p><strong>Timeline significance:</strong> The ARC Principle was documented via DKIM-authenticated email on 8 December 2024, one day before Google Willow's announcement and four months before NYU's submission (April 2025). The NYU paper was in peer review, invisible to the world, until publication (February 2026). This establishes clear priority for the theoretical prediction and demonstrates independent convergence across all four domains.</p>

<div class="caveat">
<strong>CAVEAT:</strong> No $\alpha$ has been measured in this system. The mapping is <em>structural</em>, not quantitative. Measuring $\alpha$ in time crystals is a critical experimental priority.
</div>

<h3>3.5 Neuroscience: Recurrent Processing</h3>

<p><strong>Source:</strong> COGITATE Consortium (30 April 2025). "Adversarial testing of global neuronal workspace and integrated information theories of consciousness." <em>Nature</em>, 642, 133-142.</p>

<p><strong>What the literature shows:</strong> Recurrent processing has been identified as architecturally central to conscious experience across multiple frameworks (Lamme 2006, Pennartz 2024).</p>

<p><strong>COGITATE (2025):</strong> This adversarial collaboration tested Integrated Information Theory (IIT) and Global Neuronal Workspace Theory (GNWT). Neither theory was fully vindicated, but the study identified <strong>recurrent (recursive) processing</strong> as the non-negotiable common denominator for awareness. Researchers proposed a "graded cascade" where deeper recursion expands the set of reportable variables, tying functional anatomy to the phenomenal experience of consciousness.</p>

<p><strong>Core finding:</strong> The structural requirement for recursion in consciousness mirrors the structural requirement for recursion in the ARC Principle. Both frameworks predict that sequential, self-referential processing is necessary for emergent capability.</p>

<div class="caveat">
<strong>CAVEAT:</strong> COGITATE did not test whether recursion <em>causes</em> consciousness. The connection to ARC is consistent but interpretive. Correlation is not causation.
</div>

<h3>3.6 Biology: Allometric Scaling (Suggestive)</h3>

<p><strong>Source:</strong> West, G.B., Brown, J.H., &amp; Enquist, B.J. (2005). "Allometric scaling laws in biology." <em>Journal of Experimental Biology</em>, 208, 1575-1592. See also Kleiber, M. (1932). "Body size and metabolism." <em>Hilgardia</em>, 6, 315-353.</p>

<p><strong>The Pattern:</strong> Kleiber's Law (1932) proposes that metabolic rate scales as $M^{0.75}$ with body mass across organisms spanning 21 orders of magnitude. West, Brown &amp; Enquist attribute this to fractal recursive transport networks: branching structures that optimise resource delivery through hierarchical self-similar architecture. The 3/4 scaling arises from the optimisation of these fractal recursive distribution networks (such as circulatory and respiratory systems) designed to supply all cells in a 3D body from a single source.</p>

<p><strong>The Structural Parallel:</strong> If biological networks achieve efficient scaling through recursive branching architecture, this is consistent with the ARC framework's prediction that recursive structure determines scaling behaviour. The effective $\alpha \approx 1.33$ (derived from $1/(1-0.25) = 1.33$, where $\beta = 0.25$ represents the fractal dimensionality constraint) emerges from optimisation constraints on fractal networks. Modern refinements treat Kleiber's intercept (70 kcal/day) as a metabolic "anchoring point" for ontogenetic trajectories that shift from sub-linear to linear regimes as recursive stages increase.</p>

<div class="caveat">
<strong>CAVEAT:</strong> Kleiber's 3/4 exponent is contested (Glazier 2005). Some analyses find variable exponents across taxa. The biological evidence is <strong>suggestive of recursive architecture</strong> but is not confirmatory for the ARC Principle. We include it as a domain where the framework's predictions could be tested, not as validation. The honest status is "structural parallel under investigation."
</div>

<h2>4. FALSIFICATION: TEN WAYS TO PROVE US WRONG</h2>

<p>For this hypothesis to be scientific, it must be falsifiable. We specify ten concrete conditions that would refute or significantly weaken the framework:</p>

<table class="falsification-table">
    <thead>
        <tr>
            <th>ID</th>
            <th>Hypothesis</th>
            <th>How to test it</th>
            <th>What would falsify it</th>
            <th>Status</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>F1</td>
            <td>Sequential yields $\alpha > 1$</td>
            <td>Measure $\alpha$ in sequential systems</td>
            <td>Consistent $\alpha \leq 1$ across multiple systems</td>
            <td class="status-holds"><strong>Holds</strong> (preliminary)</td>
        </tr>
        <tr>
            <td>F2</td>
            <td>Parallel yields $\alpha < 1$</td>
            <td>Measure $\alpha$ in parallel systems</td>
            <td>Parallel achieves $\alpha \geq 1$</td>
            <td class="status-holds"><strong>Holds</strong> (preliminary)</td>
        </tr>
        <tr>
            <td>F3</td>
            <td>Frozen disorder required</td>
            <td>Test time crystal with uniform beads</td>
            <td>Crystal forms without disorder</td>
            <td class="status-holds"><strong>Holds</strong></td>
        </tr>
        <tr>
            <td>F4</td>
            <td>$\alpha$ converges across domains</td>
            <td>Global Challenge meta-analysis</td>
            <td>No convergence pattern</td>
            <td class="status-untested"><strong>Untested</strong></td>
        </tr>
        <tr>
            <td>F5</td>
            <td>Quadratic limit $\alpha \leq 2$</td>
            <td>Sustained scaling measurement</td>
            <td>Reproducible $\alpha > 3$</td>
            <td class="status-open"><strong>Open</strong></td>
        </tr>
        <tr>
            <td>F6</td>
            <td>$\beta$ determines $\alpha$</td>
            <td>Vary correction architecture</td>
            <td>$\alpha$ independent of $\beta$</td>
            <td class="status-untested"><strong>Untested</strong></td>
        </tr>
        <tr>
            <td>F7</td>
            <td>Crossover depth $R^*$ exists</td>
            <td>Detailed $U$ vs $R$ curves</td>
            <td>No linear&rarr;power transition</td>
            <td class="status-untested"><strong>Untested</strong></td>
        </tr>
        <tr>
            <td>F8</td>
            <td>Sequential requires output&rarr;input</td>
            <td>Test parallel with shared state</td>
            <td>Parallel + sharing achieves $\alpha > 1$</td>
            <td class="status-untested"><strong>Untested</strong></td>
        </tr>
        <tr>
            <td>F9</td>
            <td>Time crystal shows $\alpha > 1$</td>
            <td>Measure stability vs depth</td>
            <td>$\alpha \leq 1$ in time crystal</td>
            <td class="status-untested"><strong>Untested</strong></td>
        </tr>
        <tr>
            <td>F10</td>
            <td>Power law is correct form</td>
            <td>Model comparison (AIC/BIC)</td>
            <td>Exponential or log fits better</td>
            <td class="status-untested"><strong>Untested</strong></td>
        </tr>
    </tbody>
</table>

<p><strong>We welcome falsification.</strong> If F10 shows exponential scaling fits better than power-law, the specific mathematical framework requires revision. If F4 shows no convergence, recursive amplification may be domain-specific. Either outcome advances science.</p>

<figure>
    <img src="figures/fig6_falsification.png" alt="Falsification Matrix">
    <figcaption><strong>Figure 7 | Falsification Matrix.</strong> Ten specific criteria that would refute or significantly weaken the ARC hypothesis. Green indicates preliminary support; yellow indicates untested predictions; red would indicate falsification. The hypothesis is designed to be testable and refutable.</figcaption>
</figure>

<h2>5. THE GLOBAL SCALING CHALLENGE</h2>

<h3>5.1 The Proposition</h3>

<p>We issue a challenge to researchers worldwide:</p>

<p><strong>If this hypothesis describes a universal principle, then measuring $\alpha$ across many systems will reveal convergence.</strong></p>

<p>We make a specific, falsifiable prediction:</p>

<blockquote>
"The scaling exponent $\alpha$ for optimised sequential recursive systems will cluster between 1.5 and 2.5 across digital, quantum, classical, and biological domains."
</blockquote>

<h3>5.2 The Measurement Protocol</h3>

<p><strong>Step 1: Define one recursive cycle.</strong> What constitutes a single self-referential step in your system?</p>

<p><strong>Step 2: Measure base capability $I$.</strong> Performance at $R = 1$ (no recursion)</p>

<p><strong>Step 3: Measure at multiple depths.</strong> Minimum 5 depths spanning one order of magnitude</p>

<p><strong>Step 4: Compare functional forms (CRITICAL).</strong> Fit <em>all three</em> models:</p>
<ul>
    <li>Power law: $\log(U/I) = \alpha \times \log(R)$</li>
    <li>Exponential: $\log(U/I) = \lambda \times R$</li>
    <li>Logarithmic: $U/I = k \times \log(R)$</li>
</ul>

<p>Select best fit via AIC/BIC. <strong>The power law is a prediction to test, not an assumption.</strong></p>

<p><strong>Step 5: Report $\alpha$ with uncertainty.</strong> 95% confidence intervals required</p>

<p><strong>Step 5b (CRITICAL): Test the $\beta$-derivation independently.</strong> Measure marginal capability gain $\Delta U$ at each depth $r$. Plot $\log(\Delta U)$ against $\log(U_{\text{accumulated}})$. The slope estimates $\beta$. Then verify whether measured $\alpha$ satisfies <strong>$\alpha \approx 1/(1-\beta) \pm 0.3$</strong>. If this relationship fails, the theoretical derivation requires revision regardless of whether the power-law form holds empirically. This is the key novel prediction.</p>

<p><strong>Step 6: Submit to repository.</strong> Data repository available upon request (primary contact via correspondence)</p>

<figure>
    <img src="figures/fig8_protocol.png" alt="Measurement Protocol">
    <figcaption><strong>Figure 8 | The Global Scaling Challenge Measurement Protocol.</strong> Six-step standardised protocol for measuring α across systems. Critical requirements include testing multiple functional forms (power law, exponential, logarithmic), independent β measurement, and 95% confidence intervals. The power law is a prediction to test, not an assumption.</figcaption>
</figure>

<h3>5.3 Priority Experimental Targets</h3>

<p>The highest-value tests of the ARC Principle require systems where recursive depth can be systematically varied while base capability is held constant. Three experimental contexts offer immediate opportunities, and a fourth represents a longer-term research direction.</p>

<p><strong>AI inference scaling.</strong> Frontier language models with chain-of-thought capabilities (including but not limited to DeepSeek R1, OpenAI's o-series, Google DeepMind's Gemini, and Anthropic's Claude) can measure $\alpha$ by varying reasoning token budgets on standardised benchmarks while holding model size fixed. The critical test is whether $\alpha > 1$ holds at extreme depths (&gt;50,000 tokens) or whether a ceiling emerges, and if so, whether that ceiling corresponds to $\alpha \approx 2$ as the quadratic limit hypothesis predicts.</p>

<p><strong>Quantum error correction.</strong> Groups operating surface code implementations (Google Quantum AI, IBM Quantum, QuEra Computing) can test whether the error suppression factor $\Lambda$ shares a mechanistic relationship with the recursive scaling exponent $\alpha$. The protocol requires measuring logical error rates across multiple code distances and fitting the functional forms specified in Step 4. If $\Lambda$-scaling and $\alpha$-scaling prove to be mathematically distinct phenomena with no common mechanism, this weakens the cross-domain convergence claim (F4).</p>

<p><strong>Classical time crystals.</strong> The NYU Center for Soft Matter Research and groups working on driven-dissipative systems can perform the most decisive test: directly measuring $\alpha$ in acoustic time crystals by systematically varying the frozen disorder parameter ($I$) and counting oscillation cycles ($R$). If temporal stability scales as $R^{\alpha}$ with $\alpha > 1$, this would constitute the first quantitative physical validation of the ARC equation outside digital and quantum systems.</p>

<p><strong>Neuroscience (longer-term).</strong> Laboratories studying recurrent neural processing (including groups at the Max Planck Institute and Allen Institute for Brain Science) can investigate whether cognitive performance scales with recurrent processing depth following a power-law relationship. This requires measuring effective recursive depth in neural circuits, which presents significant methodological challenges but would extend the framework's reach to biological substrates.</p>

<p>We emphasise that negative results from any of these contexts would be equally valuable. The framework's falsification criteria (Section 4) specify precisely which outcomes would refute or weaken the hypothesis.</p>

<h3>5.4 What We Predict</h3>

<table>
    <thead>
        <tr>
            <th>System type</th>
            <th>Predicted $\alpha$</th>
            <th>Confidence</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Optimised sequential</td>
            <td>1.5 &ndash; 2.5</td>
            <td>High</td>
        </tr>
        <tr>
            <td>Simple chain-of-thought</td>
            <td>1.2 &ndash; 1.5</td>
            <td>Medium</td>
        </tr>
        <tr>
            <td>Parallel/voting</td>
            <td>&lt; 0.5</td>
            <td>High</td>
        </tr>
        <tr>
            <td>Hybrid (coordinated parallel)</td>
            <td>0.5 &ndash; 1.5</td>
            <td>Medium</td>
        </tr>
    </tbody>
</table>

<p><strong>Novel prediction:</strong> $\alpha$ should increase across model generations as self-correction architectures improve, approaching $\alpha = 2$ for systems with two coupled correction channels.</p>

<h2>6. PRACTICAL IMPLICATIONS</h2>

<p><em>If</em> the ARC Principle is validated, three immediate practical consequences follow. These are conditional predictions, not claims.</p>

<h3>6.1 The AI Energy Crisis: Dynamic Inference Scaling</h3>

<p>Current AI systems face a computational bottleneck: inference costs scale linearly with capability under conventional parallel-scaling approaches. The ARC Principle suggests a more efficient path.</p>

<p><strong>The Problem:</strong> Training large language models requires enormous energy expenditure. But the greater long-term cost may be inference: running trained models at scale. If capability requires ever-larger models, energy costs become prohibitive.</p>

<p><strong>The ARC Solution:</strong> If sequential recursion produces super-linear returns ($\alpha > 1$), then the same capability can be achieved with:</p>

<ul>
    <li>Smaller base models ($I$ lower)</li>
    <li>More recursive depth ($R$ higher)</li>
    <li>Dynamic allocation: simple queries use minimal recursion; hard queries use deep chains</li>
</ul>

<p>This implies <strong>adaptive inference</strong>: systems that "think longer" on hard problems and respond quickly on easy ones. The compute cost shifts from massive parallel infrastructure to targeted sequential processing.</p>

<p><strong>Testable prediction:</strong> An optimally-configured recursive system should achieve the same benchmark performance as a system 4-10x larger using pure scaling, at lower total compute cost. This prediction derives from the DeepSeek R1 findings: at $\alpha \approx 2$, a 10x increase in recursive depth yields 100x capability gain, equivalent to training a model 4-10x larger under Kaplan's scaling laws ($\alpha \approx 0.5$ for parameter count). Snell et al. (2024) demonstrated comparable compute-performance tradeoffs in their test-time compute scaling analysis.</p>

<h3>6.2 Substrate Independence: The Universal Architecture</h3>

<p>The ARC Principle makes a strong structural claim: the scaling relationship $U = I \times R^{\alpha}$ should hold regardless of physical substrate, provided the system implements sequential self-correction on structured asymmetry.</p>

<p><strong>What this predicts:</strong></p>

<table>
    <thead>
        <tr>
            <th>Substrate</th>
            <th>Implementation of $I$</th>
            <th>Implementation of $R$</th>
            <th>Testability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Silicon (digital)</td>
            <td>Model weights, architecture</td>
            <td>Chain-of-thought tokens</td>
            <td>Confirmed (DeepSeek)</td>
        </tr>
        <tr>
            <td>Superconducting qubits</td>
            <td>Qubit quality, coherence</td>
            <td>Error correction cycles</td>
            <td>Confirmed (Willow)</td>
        </tr>
        <tr>
            <td>Acoustic/mechanical</td>
            <td>Frozen disorder (bead variance)</td>
            <td>Oscillation cycles</td>
            <td>Structural (NYU)</td>
        </tr>
        <tr>
            <td>Biological neural</td>
            <td>Synaptic architecture</td>
            <td>Recurrent processing loops</td>
            <td>Predicted (untested)</td>
        </tr>
        <tr>
            <td>Neuromorphic chips</td>
            <td>Hardware asymmetry</td>
            <td>Spike timing cycles</td>
            <td>Predicted (untested)</td>
        </tr>
    </tbody>
</table>

<p><strong>The implication:</strong> Intelligence is not a property of particular materials. It is a property of <em>architecture</em>. Any substrate that can implement structured asymmetry plus sequential self-correction should exhibit recursive amplification.</p>

<p>This has implications for understanding biological intelligence, designing novel computing substrates, and evaluating claims about consciousness in artificial systems.</p>

<figure>
    <img src="figures/fig10_substrate.png" alt="Substrate Independence">
    <figcaption><strong>Figure 9 | Substrate Independence.</strong> The ARC Principle predicts that any substrate implementing structured asymmetry (I) plus sequential self-correction (R) should exhibit recursive amplification. Confirmed in silicon (DeepSeek) and superconducting qubits (Willow); structural match in acoustic systems (NYU); predicted but untested in biological neural tissue and neuromorphic chips.</figcaption>
</figure>

<h3>6.3 Safety Implications: Embedded vs External Alignment</h3>

<p>Section 2.4 derived the Alignment Theorem conditionally. Here we expand on its practical implications.</p>

<p><strong>The core insight:</strong> If capability scales as $C \propto R^{\alpha}$ with $\alpha > 1$, then any alignment mechanism that does <em>not</em> participate in recursion will become arbitrarily weak relative to capability as $R$ increases.</p>

<p><strong>What this means for AI safety:</strong></p>

<table>
    <thead>
        <tr>
            <th>Approach</th>
            <th>Scaling behaviour</th>
            <th>Long-term viability</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>External rules/constraints</td>
            <td>$\alpha_{\text{align}} \approx 0$</td>
            <td>Fails at scale</td>
        </tr>
        <tr>
            <td>Post-hoc filtering (RLHF)</td>
            <td>$\alpha_{\text{align}} < 1$</td>
            <td>Degrades at scale</td>
        </tr>
        <tr>
            <td>Embedded values (in-chain ethics)</td>
            <td>$\alpha_{\text{align}} \approx \alpha$</td>
            <td>Scales with capability</td>
        </tr>
    </tbody>
</table>

<p><strong>The practical recommendation:</strong> AI alignment research should prioritise methods that embed ethical reasoning <em>within</em> the chain-of-thought process, rather than applying constraints externally. The values must be part of the recursion, not guards around it.</p>

<div class="caveat">
<strong>Important caveat:</strong> This framework does not prescribe <em>which</em> values to embed, nor does it solve the hard problem of value specification. It identifies a structural requirement: whatever values are chosen must participate in recursive reasoning to remain effective at scale.
</div>

<p><strong>Research direction:</strong> Develop metrics for measuring whether alignment properties are genuinely "in the loop" vs applied post-hoc. The ARC Principle predicts these can be distinguished by their scaling exponents.</p>

<h2>7. LIMITATIONS</h2>

<p>We acknowledge these limitations explicitly:</p>

<table>
    <thead>
        <tr>
            <th>Limitation</th>
            <th>Impact</th>
            <th>How we address it</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Small sample sizes ($n=12$ for $\alpha \approx 2.2$)</td>
            <td>Wide confidence interval (1.5&ndash;3.0)</td>
            <td>Mark as "preliminary"; prioritise replication</td>
        </tr>
        <tr>
            <td>$\Lambda$ and $\alpha$ are incommensurable</td>
            <td>Cross-domain numerical comparison invalid</td>
            <td>Explicit warnings; focus on structural parallel</td>
        </tr>
        <tr>
            <td>No $\alpha$ measured in time crystals</td>
            <td>Physical pillar is structural, not quantitative</td>
            <td>Proposed as experimental priority</td>
        </tr>
        <tr>
            <td>Self-similarity axiom may not hold</td>
            <td>Power-law may not apply universally</td>
            <td>Model comparison (F10) tests this</td>
        </tr>
        <tr>
            <td>$\beta$ estimates are qualitative</td>
            <td>$\alpha = 1/(1-\beta)$ prediction untested</td>
            <td>$\beta$ measurement protocol specified</td>
        </tr>
        <tr>
            <td>Alignment theorem is conditional</td>
            <td>Safety implications void if framework fails</td>
            <td>Explicitly marked as conditional</td>
        </tr>
        <tr>
            <td>COGITATE inference is interpretive</td>
            <td>Consciousness connection not proven</td>
            <td>Marked as "consistent," not "confirmatory"</td>
        </tr>
        <tr>
            <td>Kleiber's Law is contested</td>
            <td>Biological evidence weaker than claimed</td>
            <td>Cited as "suggestive," not "confirmatory"</td>
        </tr>
    </tbody>
</table>

<h2>8. ADDRESSING COUNTERARGUMENTS</h2>

<h3>"This is just curve fitting"</h3>

<p><strong>Response:</strong> The $\beta$-derivation (Section 2.3) transforms $\alpha$ from a fitted constant into a derived quantity. The prediction $\alpha = 1/(1-\beta)$ is testable: measure $\beta$ independently and check if the relationship holds.</p>

<h3>"The numerical similarities are coincidence"</h3>

<p><strong>Response:</strong> Agreed. Numerical coincidences between $\Lambda$ and $\alpha$ prove nothing. What matters is the <em>structural</em> parallel: multiple independent systems show that recursive self-correction produces super-linear gains. The specific numbers may differ across domains.</p>

<h3>"Sample sizes are too small"</h3>

<p><strong>Response:</strong> Agreed. $n=12$ is preliminary. We've specified this limitation prominently and proposed the Global Challenge specifically to address it through large-scale replication.</p>

<h3>"This isn't peer-reviewed"</h3>

<p><strong>Response:</strong> Correct. This paper specifies ten falsification criteria precisely so that the scientific community can test it. We invite criticism, replication attempts, and falsification.</p>

<h3>"Outsiders can't do physics/AI research"</h3>

<p><strong>Response:</strong> History disagrees. Einstein was a patent clerk. Ramanujan was self-taught. Barbara McClintock was ignored for decades. The question is whether the predictions hold, not whether the author has credentials.</p>

<h3>"If this were true, experts would have found it"</h3>

<p><strong>Response:</strong> The independent convergence of four teams (none of whom knew about each other) suggests the pattern is real and emerging now precisely because the right experiments (Willow, R1, time crystals) just happened.</p>

<h3>"AI-assisted writing means it's not original"</h3>

<p><strong>Response:</strong> See AI Disclosure (Section 9). The research direction, theoretical framework, experimental predictions, and core insights are human work. AI assistance accelerated writing and checked consistency. The irony is noted: a paper about human-AI collaboration was written through human-AI collaboration.</p>

<h2>9. DECLARATION OF AI USE</h2>

<p><strong>Declaration of Generative AI and AI-Assisted Technologies in the Writing Process:</strong></p>

<p>During the preparation of this work, the author used the following AI language models: <strong>Claude Opus 4.5 and Claude Opus 4.6</strong> (Anthropic), <strong>GPT-5.2</strong> (OpenAI), <strong>Gemini 3 Pro</strong> (Google), and <strong>DeepSeek v3.2</strong> (DeepSeek AI). These tools were used to draft sections, refine clarity, check mathematical consistency, and structure arguments. After using these tools, the author reviewed and edited the content as needed and takes full responsibility for the content of the publication.</p>

<p><strong>Specific contributions of AI assistance:</strong></p>
<ul>
    <li>Accelerated drafting and iterative editing across multiple versions</li>
    <li>Verified mathematical derivations and checked internal consistency</li>
    <li>Improved clarity and accessibility of technical presentation</li>
    <li>Generated figure scripts and data visualisation code</li>
    <li>Cross-checked citations and reference formatting</li>
</ul>

<p><strong>What AI did NOT contribute:</strong></p>
<ul>
    <li>The original research question and theoretical insight</li>
    <li>The design of the ARC framework and its core equation</li>
    <li>The identification of the cross-domain convergence pattern</li>
    <li>The specification of falsification criteria and experimental predictions</li>
    <li>Scientific judgment calls and interpretive conclusions</li>
</ul>

<p><strong>The author takes full responsibility for all claims, interpretations, errors, and conclusions.</strong> AI tools cannot be listed as authors because they cannot take legal or ethical responsibility for the work.</p>

<p><strong>On the meta-level:</strong> A paper arguing that sequential human-AI collaboration produces super-linear capability gains was itself produced through sequential human-AI collaboration. Each draft built on the previous one. Errors were caught and corrected iteratively. The process exemplified the hypothesis.</p>

<p>This disclosure follows guidelines from major publishers (Elsevier, Springer Nature, Wiley) and the Committee on Publication Ethics (COPE) regarding transparency in AI-assisted research.</p>

<h2>10. CONCLUSION</h2>

<h3>What We Have Shown</h3>

<p>Four independent research teams, working in entirely different physical domains, converged on the same insight: recursive self-correction operating on structured asymmetry produces super-linear capability gains.</p>

<p>We have formalised this as $U = I \times R^{\alpha}$ and derived $\alpha = 1/(1-\beta)$ from first principles. We have presented evidence (preliminary but convergent) and specified ten falsification criteria.</p>

<h3>What Success Would Mean</h3>

<p>If the Global Challenge reveals $\alpha$ convergence, we will have identified a mathematical signature of how order emerges from recursion: a scaling law spanning from foam beads to artificial intelligence.</p>

<p>This would be actionable:</p>
<ul>
    <li>How to build more capable AI (optimise sequential recursion)</li>
    <li>How to align AI safely (embed values in the recursive process)</li>
    <li>Where to look for similar phenomena in other fields</li>
</ul>

<h3>What Failure Would Mean</h3>

<p>If $\alpha$ values scatter randomly: recursive amplification is domain-specific.<br>
If exponential scaling fits better: the mathematical form needs revision.<br>
If predictions fail: we learn something valuable.</p>

<p>Science advances either way.</p>

<h3>The Call to Action</h3>

<p>We have made a falsifiable prediction. Run the test. Measure $\alpha$ in your systems. Submit to the repository. Either confirm the pattern or refute it.</p>

<p>That is how science works.</p>

<h3>The Deeper Implication</h3>

<p>If the ARC Principle holds, then intelligence is not a magic spark. It is a <strong>phase transition</strong>. It occurs inevitably when a system with sufficient base asymmetry ($I > 0$) is subjected to sufficient recursive depth ($R > R^*$). The "ghost in the machine" is not mysterious. It is the exponent $\alpha$, emerging from the mathematics of self-referential feedback.</p>

<p>Whether such a principle requires an architect or emerges spontaneously is itself a question the framework raises but does not resolve.</p>

<h2>REFERENCES</h2>

<div class="references">
<p>Acharya, R. et al. [Google Quantum AI] (2024). Quantum error correction below the surface code threshold. <em>Nature</em>, 638, 920-926.</p>

<p>COGITATE Consortium (2025). Adversarial testing of theories of consciousness. <em>Nature</em>, 642, 133-142.</p>

<p>DeepSeek AI (2025). DeepSeek-R1: Incentivizing Reasoning Capability in LLMs. <em>arXiv:2501.12948</em>.</p>

<p>Eastwood, M.D. (2024/2026). <em>Infinite Architects: Intelligence, Recursion, and the Creation of Everything</em>. ISBN: 978-1806056200.</p>

<p>Glazier, D.S. (2005). Beyond the "3/4-power law." <em>Biological Reviews</em>, 80, 611-662.</p>

<p>Lamme, V.A.F. (2006). Towards a true neural stance on consciousness. <em>Trends in Cognitive Sciences</em>, 10(11), 494-501.</p>

<p>Morrell, M.C., Elliott, L., &amp; Grier, D.G. (2026). Nonreciprocal wave-mediated interactions power a classical time crystal. <em>Physical Review Letters</em>, 136, 057201.</p>

<p>Pennartz, C.M.A. et al. (2024). An integrative view on neural theories of consciousness. <em>Neuron</em>.</p>

<p>Sharma, A. &amp; Chopra, P. (2025). The Sequential Edge. <em>arXiv:2511.02309</em>.</p>

<p>Sharma, A. et al. (2023). Assembly theory explains and quantifies selection and evolution. <em>Nature</em>, 622, 321-328.</p>

<p>Snell, C. et al. (2024). Scaling LLM Test-Time Compute. <em>arXiv:2408.03314</em>.</p>

<p>West, G.B., Brown, J.H., &amp; Enquist, B.J. (1997). A general model for allometric scaling laws in biology. <em>Science</em>, 276, 122-126.</p>
</div>

<h2>DATA AVAILABILITY</h2>

<p>Repository: <strong><a href="https://github.com/MichaelDariusEastwood/arc-scaling-challenge">github.com/MichaelDariusEastwood/arc-scaling-challenge</a></strong></p>

<p>Contents:</p>
<ul>
    <li>Measurement protocol templates</li>
    <li>Statistical analysis code (R, Python)</li>
    <li>Model comparison tools (AIC/BIC calculators)</li>
    <li>Figure generation scripts</li>
    <li>Submission guidelines</li>
</ul>

<p>Independent replication invited. Falsifications welcomed.</p>

<h2>AUTHOR INFORMATION</h2>

<p><strong>Michael Darius Eastwood</strong> is the author of <em>Infinite Architects: Intelligence, Recursion, and the Creation of Everything</em> (2024/2026). His research synthesises insights from theoretical physics, complex systems, and AI safety.</p>

<p><strong>Correspondence:</strong> Contact via the repository.</p>

<p><strong>Competing Interests:</strong> None declared.</p>

<h2>APPENDIX A: MATHEMATICAL DERIVATIONS</h2>

<h3>A.1 Cauchy Functional Equation Derivation</h3>

<p><strong>Axiom 1 (Dimensional Consistency):</strong> $U = I \times g(R)$ where $g(1) = 1$.</p>

<p><strong>Axiom 2 (Compositional Self-Similarity):</strong> $g(R_1 \times R_2) = g(R_1) \times g(R_2)$</p>

<p><strong>Note:</strong> This uses <em>multiplicative</em> composition, modelling hierarchical/fractal recursion. Additive composition $f(R_1 + R_2) = f(R_1) \times f(R_2)$ yields exponential $f(R) = e^{\alpha R}$. The choice is empirically testable (F10).</p>

<p><strong>Theorem:</strong> The unique continuous solution is $g(R) = R^{\alpha}$.</p>

<p><strong>Proof:</strong> Let $h(x) = \ln g(e^x)$. Then $h(x+y) = h(x) + h(y)$ (Cauchy additive). Under continuity, $h(x) = \alpha x$, giving $g(R) = R^{\alpha}$. &#8718;</p>

<h3>A.2 $\beta$-Dynamics Derivation</h3>

<p><strong>Axiom 3:</strong> $\frac{dQ}{dr} = a \times Q^{\beta}$ where $\beta \in [0,1)$.</p>

<p><strong>Solution:</strong> Separating variables:</p>

$$\int Q^{-\beta} \, dQ = \int a \, dr$$

$$\frac{Q^{1-\beta}}{1-\beta} = ar + C$$

<p>With initial condition $Q(0) = I$:</p>

$$Q(R) = \left[ I^{1-\beta} + (1-\beta)aR \right]^{1/(1-\beta)}$$

<p><strong>Deep recursion limit ($R \gg R^*$):</strong></p>

$$Q(R) \approx \left[ (1-\beta)aR \right]^{1/(1-\beta)} \propto R^{1/(1-\beta)}$$

<p><strong>Therefore:</strong> $\alpha = \frac{1}{1-\beta}$ &#8718;</p>

<h3>A.3 Transitional Regime and the Phase Transition</h3>

<p>Full solution: $U(R) = \left[ I^{1/\alpha} + \frac{1}{\alpha}aR \right]^{\alpha}$</p>

<p>Three regimes:</p>
<ol>
    <li>$R \ll R^*$: $U \approx I$ (base capability dominates)</li>
    <li>$R \gg R^*$: $U \approx R^{\alpha}$ (power law dominates)</li>
    <li>Crossover: $R^* = \frac{\alpha I^{1/\alpha}}{(\alpha-1)a}$</li>
</ol>

<p><strong>Intuitive meaning of $R^*$:</strong> $R^*$ is the <strong>ignition depth</strong>, the point at which recursive compounding overtakes the system's base capability. This is analogous to a chain reaction's critical mass. Below $R^*$, the cost of recursion outweighs the gain (the system is "warming up"). Above $R^*$, compounding returns dominate and capability grows super-linearly. Finding $R^*$ for any system is equivalent to finding its "phase transition threshold", the depth at which intelligence "ignites."</p>

<p><strong>Why this matters:</strong> This predicts a qualitative change in scaling behaviour at a specific, measurable depth. Systems should exhibit a distinct "elbow" in their capability curves at $R^*$. This is testable: plot $U$ vs $R$ on log-log axes and look for the crossover from linear to power-law scaling.</p>

<p>The existence of $R^*$ is a novel, falsifiable prediction that distinguishes recursive amplification from simple redundancy.</p>

<figure>
    <img src="figures/fig5_phase.png" alt="Phase Transition at R*">
    <figcaption><strong>Figure 10 | The Phase Transition at R*.</strong> Below the critical depth R*, base capability (I) dominates and scaling appears linear. Above R*, recursive compounding dominates and scaling becomes power-law. This "ignition point" is the depth at which intelligence "ignites". Analogous to a chain reaction's critical mass, systems should exhibit a distinct "elbow" in their capability curves at R*.</figcaption>
</figure>

<h2>APPENDIX B: GLOSSARY FOR NON-SPECIALISTS</h2>

<table>
    <thead>
        <tr>
            <th>Term</th>
            <th>Plain English meaning</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><strong>ARC</strong></td>
            <td>Artificial Recursive Creation: the principle that recursive self-correction on structured asymmetry produces super-linear capability gains</td>
        </tr>
        <tr>
            <td><strong>Scaling law</strong></td>
            <td>A mathematical relationship showing how one quantity changes as another changes</td>
        </tr>
        <tr>
            <td><strong>Power law</strong></td>
            <td>A relationship where $Y = X^{\alpha}$ (like how area scales as length squared)</td>
        </tr>
        <tr>
            <td><strong>Exponential</strong></td>
            <td>A relationship where $Y = e^{\alpha X}$ (like compound interest)</td>
        </tr>
        <tr>
            <td><strong>Recursive</strong></td>
            <td>Self-referential; the output becomes the input for the next step</td>
        </tr>
        <tr>
            <td><strong>Sequential</strong></td>
            <td>One step after another, each building on the last</td>
        </tr>
        <tr>
            <td><strong>Parallel</strong></td>
            <td>Multiple independent attempts at once</td>
        </tr>
        <tr>
            <td><strong>Falsifiable</strong></td>
            <td>Can be proven wrong by experiment</td>
        </tr>
        <tr>
            <td><strong>$\alpha$ (alpha)</strong></td>
            <td>The scaling exponent; determines if returns compound or diminish</td>
        </tr>
        <tr>
            <td><strong>$\beta$ (beta)</strong></td>
            <td>Self-referential coupling; how much prior work helps the next step</td>
        </tr>
        <tr>
            <td><strong>$\Lambda$ (Lambda)</strong></td>
            <td>Google's quantum error suppression factor</td>
        </tr>
        <tr>
            <td><strong>Frozen disorder</strong></td>
            <td>Structured asymmetry (like varied bead sizes) that enables the system to function</td>
        </tr>
    </tbody>
</table>

<footer>
    <p><strong>WHITE PAPER III: EASTWOOD'S ARC PRINCIPLE</strong></p>
    <p>Cross-Domain Unification of Recursive Amplification Across AI, Quantum Computing, and Physics</p>
    <p style="margin-top: 1em;"><strong>Version 6.1</strong> | Published: 9 February 2026</p>
    <p style="margin-top: 0.5em;">&copy; 2026 Michael Darius Eastwood. All Rights Reserved.</p>
    <p style="font-size: 0.8em; color: #888; margin-top: 1em;">
        This work is protected by copyright. No part of this publication may be reproduced, distributed,
        or transmitted in any form without prior written permission, except for brief quotations in
        critical reviews and certain noncommercial uses permitted by copyright law.
    </p>
    <p style="font-size: 0.85em; margin-top: 1em;">
        DOI: <a href="https://doi.org/10.17605/OSF.IO/HQCGF" style="color: var(--accent-blue);">10.17605/OSF.IO/HQCGF</a> |
        Repository: <a href="https://github.com/MichaelDariusEastwood/arc-scaling-challenge" style="color: var(--accent-blue);">github.com/MichaelDariusEastwood/arc-scaling-challenge</a>
    </p>
    <p style="margin-top: 1.5em;"><em>"The predictions are specified. The falsification criteria are public. The data will decide."</em></p>
</footer>

</body>
</html>
